- name: Clean copy
  file: path="{{ downloader_root }}"
        state=absent

- name: Create directories
  file: path="{{ item }}" 
        state="directory" 
        owner="{{ dcc_user }}"
  with_items:
    - "{{ dcc_user_directory }}"
    - "{{ downloader_root }}"

- name: get dcc-downloader tarball from artifactory
  get_url:  url="{{ downloader_dist_url }}" 
            dest="{{ staging_dir }}/{{ downloader_dist_filename }}" 
            mode=644

- name: Extract dcc-downloader ==> /u/dcc_dev/dcc_downloader
  unarchive:  src="{{ staging_dir }}/{{ downloader_dist_filename }}"
              dest="{{ downloader_root }}"
              copy=no

# Patch oozie workflow configurations
- name: Patch archive
  template: src="{{ item }}.j2" 
            dest="{{ downloader_workflow_folder }}/{{ item }}" 
            mode=644 
            force=yes
  with_items:
    - archive/config-default.xml
    - archive-main/config-default.xml
    - archivecleaner-main/config-default.xml
    - archivecleaner-main/job.properties

# Copy to HDFS
# FIXME: Need to take care of coordinator jobs
- name: Remove workflow dir
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -rm -r -skipTrash /user/downloader/workflows"
  ignore_errors: yes

- name: Create workflow dir
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -mkdir /user/downloader/workflows"
  ignore_errors: yes


- name: Copy workflow dirs
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -copyFromLocal -p {{ downloader_workflow_folder }}/{{ item }} {{ downloader_user_workflow_folder }}/{{ item }}"
  with_items:
    - archive
    - archive-main
    - archivecleaner
    - archivecleaner-main
  ignore_errors: yes

- name: Change ownership
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -chown -R downloader {{ downloader_user_workflow_folder }}"
  ignore_errors: yes

- name: Create dynamic lib directory
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -mkdir -p {{ downloader_hbase_lib_folder }}"
  ignore_errors: yes

- name: Copy over filter.jar
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -copyFromLocal {{ downloader_root }}{{ downloader_hbase_lib_folder }}/filter.jar {{ downloader_hbase_lib_folder }}/filter.jar"
  ignore_errors: yes


# Copy downloader libs to hdfs for oozie workflows
# FIXME: Maybe we can just specify a lib path instead??
- name: Create lib dir
  shell: "hadoop fs -mkdir /user/downloader/workflows/{{ item }}/lib"
  with_items:
    - "archive"
    - "archivecleaner"
  environment: env
  ignore_errors: yes

- name: Copy lib to hdfs
  shell: "hadoop fs -copyFromLocal {{ downloader_workflow_folder }}/archive/lib/dcc-downloader.jar {{ downloader_user_workflow_folder }}/{{ item }}/lib/dcc-downloader.jar"
  with_items:
    - "archive"
    - "archivecleaner"
  environment: env
  ignore_errors: yes
  
- name: Make sure dcc_dev owns everything
  file: path="{{ downloader_root }}" 
        owner={{ dcc_user }}
        recurse=yes
