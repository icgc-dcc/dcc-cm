- name: Clean copy
  file: path="{{ downloader_workflows_root }}"
        state=absent

- name: get dcc-downloader_workflows tarball from artifactory
  get_url:  url="{{ downloader_workflows_dist_url }}" 
            dest="{{ staging_dir }}/{{ downloader_workflows_dist_filename }}" 
            mode=644

- name: Extract dcc-downloader-workflows ==> /u/dcc_dev/dcc-downloader-workflows
  unarchive:  src="{{ staging_dir }}/{{ downloader_workflows_dist_filename }}"
              dest="{{ dcc_home }}"
              copy=no

- name: Update the symbolic link to the distribution
  file: path="{{ downloader_workflows_root }}"
        src="{{ dcc_home }}/{{ downloader_workflows_dist_fullname }}"
        state=link 
        force=yes

- name: Patch templates
  template: src="{{ item }}.j2" 
            dest="{{ downloader_workflows_root }}/workflows/{{ item }}" 
            mode=644 
            force=yes
  with_items:
    - archive/config-default.xml
    - archive-main/config-default.xml
    - archive-maintenance-main/config-default.xml
    - archive-maintenance-main/job.properties
    - archivecleaner-main/config-default.xml
    - archivecleaner-main/job.properties

- name: Create downloader directory in hdfs
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -mkdir -p {{ downloader_user_folder }}"

- name: Copy workflow dirs
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -copyFromLocal -p -f {{ downloader_workflows_root }}/* {{ downloader_user_folder }}"

- name: Change ownership
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -chown -R downloader {{ downloader_user_folder }}"

- name: Copy over filter.jar
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -copyFromLocal -p -f {{ downloader_hbase_lib_folder }}/* {{ hbase_lib_folder }}/"

# https://github.com/ansible/ansible/issues/548
- name: Make sure dcc_dev owns everything
  file: path="{{ dcc_home }}" 
        owner={{ dcc_user }}
        recurse=yes
