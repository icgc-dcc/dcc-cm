################################################################################
#
# ETL Main Role
#
# - Install packages on main ETL Node
# - Install etl scripts, reference data on ETL node
# - Install annotator on main ETL node
# - Install reference data for annotator
# - Patch scripts and configuration files for openstack environment
# - Bootstrap dcc-genome on mongodb server
# - Install exporter on main ETL node
# - Install downloader and its workflows into the cluster
#
#
# Note this role makes assumptions of which one of hadoop nodes
# is the jobtracker, name-node, quorum..etc
# 
# TODO:
# FIXME: not a good way to handle this
# 1) Patch exporter setenv.sh 
#   - The datatype declaration should only contain the data types that we have, otherwise 
#     the dynamic exporter will throw an exception and halt the overarching script. This
#     is difficult to do programmatically as we don't know that projects have what types.
#
# 2) (Re)create oozie workflow for coordinator (archivecleaner)
#   - Goto a oozie server
#   - Copy job.properties from HDFS     hadoop fs -copyToLocal /user/downloader/workflows/archivecleaner-main/job.properties job.properties
#   - Get job id if exists     oozie jobs -oozie http://localhost:11000/oozie -jobtype coordinator
#   - Kill job if exists       oozie job -oozie http://localhost:11000/oozie -kill <Coordinator job_id from above>
#   - Install coordinator      oozie job -oozie http://localhost:11000/oozie -config job.properties -submit
#   - Start coordinator        oozie job -oozie http://localhost:11000/oozie -start <New coordinator job_id>
#
################################################################################

- name: ensure groups exist
  group:  name={{ item }}
          state=present
  with_items:
    - ubuntu
    - adm
    - dialout
    - netdev
    - admin

- name: Create dcc_dev user
  user: name="{{dcc_user}}" 
        groups="ubuntu,adm,dialout,netdev,admin"
        append=yes
        shell=/bin/bash

- name: Wipe out the scripts to get clean install
  file: path="{{ repo_dir }}"
        state=absent

- name: Create directories
  file: path="{{ item }}" 
        state="directory" 
        owner="{{dcc_user}}"
  with_items:
    - "{{ keys_dir }}"
    - "{{ repo_dir }}"
    - "{{ config_dir }}"
    - "{{ config_project_dir }}"
    - "{{ config_ditionaries_dir }}"
    - "{{ data_dir }}"
    - "{{ lib_dir }}"
    - "{{ nfs_dir }}"

- name: Install helper packages
  action: apt pkg={{ item }} 
              state=latest
              force=yes
  with_items:
    - "tree"
    - "sendemail"
    - "git"
    - "curl"
    - "inetutils-ping"

# FIXME: this is dchang's github key
- name: Copy github key
  copy: src="github-keys/id_rsa" 
        dest="{{ keys_dir }}/id_rsa"
        mode=600

# TODO: Might want to do sparse checkout
# FIXME: Use biternay's group account?
# See: http://stackoverflow.com/questions/600079/is-there-any-way-to-clone-a-git-repositorys-sub-directory-only 
- name: Download ETL scripts
  git:  repo=ssh://git@github.com/icgc-dcc/dcc-etl.git
        dest={{ repo_dir }}
        accept_hostkey=True
        key_file={{ keys_dir }}/id_rsa

# TODO: Remove this when changes are merged.
- name: Switch to cdh5.3.0 branch
  shell: "cd {{ repo_dir }} && git checkout feature/DCC-2713-cdh5.3-upgrade"

# FIXME: quickie fix for mongo on openstack
- name: Patch mongo admin 
  lineinfile: dest="{{ lisi_facade }}" 
              regexp="\s+admin_database_user="
              line="  admin_database_user=admin"

- name: Patch mongo admin password
  lineinfile: dest="{{ lisi_facade }}" 
              regexp="\s+admin_database_user_passwd="
              line="  admin_database_user_passwd=admin"

- name: Patch mongo etl user
  lineinfile: dest="{{ lisi_facade }}" 
              regexp="\s+normal_database_user="
              line="  normal_database_user=dcc"

- name: Patch mongo etl user password
  lineinfile: dest="{{ lisi_facade }}" 
              regexp="\s+normal_database_user_passwd="
              line="  normal_database_user_passwd=dcc"

- name: get dcc-etl-cli from artifactory
  get_url:  url="{{ cli_url }}" 
            dest="{{ staging_dir }}/{{ cli_jar_filename }}" 
            mode=644

- name: get dcc-etl-annotator from artifactory
  get_url:  url="{{ annotator_jar_url }}" 
            dest="{{ staging_dir }}/{{ annotator_jar_filename }}" 
            mode=644

- name: get dcc-submission-server from artifactory
  get_url:  url="{{ submission_server_jar_url }}" 
            dest="{{ staging_dir }}/{{ submission_server_jar_filename }}" 
            mode=644

- name: Copy dcc-etl-cli, dcc-submission-server and dcc-annotator jars to lib
  command: cp "{{ staging_dir }}/{{ item }}" "{{ lib_dir }}/{{ item }}"
  with_items:
    - "{{ cli_jar_filename }}"
    - "{{ submission_server_jar_filename }}"
    - "{{ annotator_jar_filename }}"

- name: Symlink dcc-etl-cli jar file
  file: src="{{ cli_jar_filename }}"
        dest="{{ lib_dir }}/dcc-etl.jar"
        state=link

- name: Symlink dcc-etl-annotator jar file
  file: src="{{ annotator_jar_filename }}"
        dest="{{ lib_dir }}/dcc-annotator.jar"
        state=link

- name: Symlink dcc-submission-validator jar file
  file: src="{{ submission_server_jar_filename }}"
        dest="{{ lib_dir }}/dcc-validator.jar"
        state=link

- name: Copy logging configuraiton
  copy: src="logback.xml" 
        dest="{{ config_dir }}/logback.xml" 
        mode=644

- name: Prepare etl configuration
  template: src=etl_prod.yaml.j2 
            dest="{{ config_dir }}/etl_prod.yaml"

- name: Create icgc dir
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -mkdir {{ hdfs_icgc_home_dir }}"
  ignore_errors: yes

- name: Create dcc_home_dir dir
  shell: "HADOOP_USER_NAME=hdfs hadoop fs -mkdir {{ hdfs_dcc_home_dir }}"
  ignore_errors: yes

- name: Give dcc_user ownership.
  file: path="{{ etl_home }}" 
        owner={{ dcc_user }} 
        recurse=yes

################################################################################
# Bootstrap ETL environment, get codelist and dictionary, setup project file, etc.
################################################################################

- name: Interpolate and copy script
  template: src=init.sh.j2 
            dest={{ etl_home }}/init.sh 
            mode=0744

- name: Assign init command to variable
  set_fact: init_command="{{ etl_home }}/init.sh {{ external_submission_url }}"
  
- name: Initialize the system
  shell: "{{ init_command }}"
  register: initLog

- debug: msg="{{ initLog.stdout }}"

  
