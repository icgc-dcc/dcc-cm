################################################################################
# Brings up DCC ETL pipeline:
#
# - Initial hosts allocation
# - Provision Openstack instances and divide into logical groups
# - Create and distribute custom host files for openstack
# - Install Postgresql database server
# - Install ICGC DCC schemas
# - Provision DCC Identifier
# - Provision MongoDB server
# - Provision ElasticSearch server
# - Copy reference data to worker nodes
# - Install LZO on worker nodes
# - Provision Cloudera Manager
#
# - >>> Manually provision the cluster through Cloudera Manager <<<
#
# - Install packages on main ETL Node
# - Install etl scripts, reference data on ETL node
# - Install annotator on main ETL node
# - Install reference data for annotator
# - Patch scripts and configuration files for openstack environment
# - Bootstrap dcc-genome on mongodb server
# - Install exporter on main ETL node
# - Install downloader and its workflows into the cluster
#
#
# Note the playbook makes assumptions of which one of hadoop nodes
# is the jobtracker, name-node, quorum..etc
#
# Usage:
#   ./runAnsible etl_main.yml <tags>
#
################################################################################



################################################################################
#
# Post provisioning steps: Do these before starting an ETL run 
#
# - Copy projects' submission files to hdfs
# - Create project.json configuration
# - Download the dictionary for the ETL run
# - Download codelist for the ETL run??
# 
# 
# FIXME: not a good way to handle this
# 1) Patch exporter setenv.sh 
#   - The datatype declaration should only contain the data types that we have, otherwise 
#     the dynamic exporter will throw an exception and halt the overarching script. This
#     is difficult to do programmatically as we don't know that projects have what types.
#
# 2) (Re)create oozie workflow for coordinator (archivecleaner)
#   - Goto a oozie server
#   - Copy job.properties from HDFS     hadoop fs -copyToLocal /user/downloader/workflows/archivecleaner-main/job.properties job.properties
#   - Get job id if exists     oozie jobs -oozie http://localhost:11000/oozie -jobtype coordinator
#   - Kill job if exists       oozie job -oozie http://localhost:11000/oozie -kill <Coordinator job_id from above>
#   - Install coordinator      oozie job -oozie http://localhost:11000/oozie -config job.properties -submit
#   - Start coordinator        oozie job -oozie http://localhost:11000/oozie -start <New coordinator job_id>
#
################################################################################

- name: Generate initial hosts
  hosts: localhost
  gather_facts: False
  tasks:
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-postgres" groups=group_01
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-identifier" groups=group_02
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-cm" groups=group_03
    - name: "Adding host"
      add_host: name="{{ item }}" groups=group_04
      with_sequence: count=4 format="{{ server_prefix }}-etl-worker-%02x"
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-mongo" groups=group_05
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-main" groups=group_06
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-elasticsearch" groups=group_07
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-test" groups=group_08
  tags:
    - first
    - debug



- name: Create Openstack host file
  hosts: localhost
  gather_facts: False
  tasks:
    - name: "Remove previous host file if exist"
      shell: rm -f bootstrap_hosts
      delegate_to: localhost
    - name: "Create new host file with localhost entry"
      shell: echo "127.0.0.1 localhost" > bootstrap_hosts
      delegate_to: localhost
  tags:
    - first
    - debug


- name: Provision OpenStack Instance
  hosts: group_01
  user: root
  gather_facts: False
  serial: 1
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} groups=postgres,all_instances hostname={{ inventory_hostname }}
  tags:
    - first
    - debug


- name: Provision OpenStack Instance
  hosts: group_02
  user: root
  gather_facts: False
  serial: 1
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} groups=identifier,all_instances hostname={{ inventory_hostname }}
  tags:
    - first
    - debug


- name: Provision OpenStack Instance
  hosts: group_03
  user: root
  gather_facts: False
  serial: 1
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} groups=manager,all_instances hostname={{ inventory_hostname }}
  tags:
    - first
    - debug


- name: Provision OpenStack Instance
  hosts: group_04
  user: root
  gather_facts: False
  serial: 1
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} groups=workers,all_instances hostname={{ inventory_hostname }}
  tags:
    - first
    - debug



- name: Provision OpenStack Instance
  hosts: group_05
  user: root
  gather_facts: False
  serial: 1
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} groups=mongo,all_instances hostname={{ inventory_hostname }}
  tags:
    - first
    - debug




- name: Provision OpenStack Instance
  hosts: group_06
  user: root
  gather_facts: False
  serial: 1
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} groups=main,all_instances hostname={{ inventory_hostname }}
  tags:
    - first
    - debug


- name: Provision OpenStack Instance
  hosts: group_07
  user: root
  gather_facts: False
  serial: 1
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} groups=elasticsearch,all_instances hostname={{ inventory_hostname }}
  tags:
    - first
    - debug





################################################################################
# Getting around openstack quirkyness of not having DNS
################################################################################
- name: Check if SSH is ready on servers
  hosts: all_instances
  gather_facts: False
  tasks:
    - name: Wait for ssh
      wait_for: host={{ inventory_hostname }} port=22 timeout=900
      delegate_to: localhost
  tags:
    - first



- name: Grab openstack node's internal IPs
  hosts: all_instances
  gather_facts: True
  serial: 1
  vars_files:
    - "vars/main.yml"
  vars:
    host_key_checking: False
    ansible_ssh_user: ubuntu
  tasks:
    - name: Writing IPs to host file
      shell: echo "{{ ansible_all_ipv4_addresses[0] }} {{ ansible_hostname }}" >> bootstrap_hosts
      delegate_to: localhost
  tags:
    - first



- name: Replace /etc/hosts with bootstrapped hosts file
  hosts: all_instances
  sudo: True
  serial: 1
  vars_files:
    - "vars/main.yml"
  vars:
    host_key_checking: False
    ansible_ssh_user: ubuntu
  tasks:
    - name: Copying... 
      copy: src=bootstrap_hosts dest=/etc/hosts owner=root group=root
  tags:
    - first




################################################################################
# Real work starts here
################################################################################
- name: Install postgresql database server
  hosts: postgres
  sudo: True
  serial: 1
  gather_facts: True
  vars_files:
    - "vars/main.yml"
  roles:
    - postgres
  tags:
    - first


- name: Bootstrap databases
  hosts: postgres
  sudo_user: postgres
  sudo: True
  serial: 1
  gather_facts: True
  vars_files:
    - "vars/main.yml"
  roles:
    - postgresData
  tags:
    - first


# Generated password for ansible postgres???
# $ echo "md5`echo -n "dccdcc" | md5`"

- name: Provision Identifier
  hosts: identifier
  sudo: True
  serial: 1
  gather_facts: True
  vars_files:
    - "vars/main.yml"
  vars:
    identifier_url: "jdbc:postgresql://{{ server_prefix }}-etl-postgres:5432/dcc_identifier"
  pre_tasks:
    - name: Install Java
      include: tasks/install-java.yml
  roles:
    - identifier
  tags:
    - first
  

- name: Setting up MongoDB
  hosts: mongo 
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  roles:
    - mongodb
  tags:
    - first


- name: Setting up Elasticsearch Node
  hosts: elasticsearch
  sudo: True
  gather_facts: False
  vars_files: 
    - "vars/main.yml"
  vars:
    # es_cluster_name: cdh_elasticsearch 
    es_cluster_name: elasticsearch 
  pre_tasks:
    - name: Install Java
      include: tasks/install-java.yml
  roles:
    - elasticsearch
  tags:
    - first



# FIXME: Production uses /u/dcc_dev/ as a shared directory, we don't have this on openstack
- name: Copy reference genome to worker ndoes
  hosts: workers
  gather_facts: False
  sudo: True
  vars_files:
    - "vars/main.yml"
  tasks:
    - name: Ensure data directory
      file: path="{{ item }}" state="directory" mode=0777 
      with_items:
        - "{{ data_dir }}"
    - name: Copy genome
      get_url: "url={{ reference_genome_url }} dest={{ data_dir }}/{{ reference_genome_archive }} mode=0777"
    - name: Extract the reference genome 
      command: "tar xzf {{ data_dir }}/{{ reference_genome_archive }} -C {{ data_dir }}"
  tags:
    - first
  
      


- name: Setting up Cloudera Manager
  hosts: manager
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - name: Setup CDH repositories
      include: tasks/install-cdh-repository.yml
    - name: update apt repositories
      action: shell apt-get update ; true
    - name: install python-apt
      raw: "apt-get install -y python-apt"
    - name: install ntp
      action: apt pkg=ntp state=latest
      notify: start ntp
    - name: install sudo
      action: apt pkg=sudo state=latest
    - name: install tree
      action: apt pkg=tree state=latest
    - name: install curl
      action: apt pkg=curl state=latest
    - name: Install Java
      include: tasks/install-java.yml
    - name: Install Cloudera Manager Server
      action: apt pkg={{ item }} state=latest
      with_items:
        - cloudera-manager-daemons
        - cloudera-manager-server-db
        - cloudera-manager-server
    - name: Start CM service
      action: service name={{ item }} state=running
      with_items:
        - cloudera-scm-server-db
        - cloudera-scm-server
    - name: Upload pem file.
      copy: src="{{ ansible_ssh_private_key_file }}" dest=/home/ubuntu/dcc.pem mode=0600
  handlers:
    - name: start ntp
      action: service name=ntp state=started
  tags:
    - first



- name: Install LZO
  hosts: main:workers
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - name: Get liblzo2-2
      apt: pkg="liblzo2-2" state=installed
    #- name: Get extra repo
    #  get_url: url="http://archive.cloudera.com/gplextras5/ubuntu/precise/amd64/gplextras/cloudera.list" dest="/etc/apt/sources.list.d/gplextras.list"
    - name: Get extra repo
      copy: src="files/gplextras.list" dest="/etc/apt/sources.list.d/gplextras.list" mode=0644 force=yes
    - name: Update apt-get 
      shell: apt-get update
    - name: Get hadoop lzo
      apt: pkg="hadoop-lzo" state=installed force=yes
    - name: Just to test, get lzop
      apt: pkg="lzop" state=installed
  tags:
    - first
    - debug




- name: Pause playbook
  hosts: localhost
  connection: local
  gather_facts: False
  tasks:
    - pause: prompt="Time to do manual work for the cluster..."
#  tags:
#    - debug


################################################################################
#
# Manual work required here
#
# 1) Use CM to provision the cluster, worker nodes need
#   - Zookeeper, HDFS, MapReduce, HBase, Oozie
#
# 2) Use CM to install HDFS client on etl main node so it can access HDFS
#   - Goto Home => HDFS => Instances 
#   - Select "Add Role Instances"
#   - Select Gateway and select the etl host
#   - Redeploy client configuration
#
# 3) Use CM to install MapReduce client on the etl main node so it can run exporter
#   - Goto Home => Map Reduce => Instances
#   - Select "Add Role Instances"
#   - Select Getway and select the etl host
#   - Redeploy client configuration
#
# 4) Use CM to install HBase client on etl main node
#
#
# FIXME: Might be a better way to do this programmatically
# 5) In cloudera manager
#   - Goto hbase configuration
#   - Search for hbase-site.xml
#   - Add the following and restart hbase service
#  
#    <property>
#      <name>hbase.dynamic.jars.dir</name>
#      <value>/hbase_lib</value>
#    </property>
#  
# See 
#   hbase.dynamic.jars.dir in http://hbase.apache.org/book.html 
#
# FIXME: Not a good solution !!!
# 6) Edit /etc/hbase/conf/hbase-site.xml in the main ETL node to get around hbase max hfile limitation
#   - Add the following to the xml
#
#    <property>
#       <name>hbase.mapreduce.bulkload.max.hfiles.perRegion.perFamily</name>
#       <value>5000</value>
#    </property>
#
#    See: http://stackoverflow.com/questions/24950393/trying-to-load-more-than-32-hfiles-to-one-family-of-one-region
#  
#   
# 6) Need to identify the name-node, task-trackers, etc for use down below
# 
#
#
################################################################################


################################################################################
#
# LZO support
#
# Need to reconfigure via cloudera manager to set io.compression, and restart
# map reduce services. Note the notes are applicable to CDH version 5.1, other versions
# may vary.
#
#
# 1) Configure compression codecs: 
# - Goto Home => MapReduce => Configuration
# - Search for "io.compression"
# - Add the following values:
#     org.apache.hadoop.io.compress.DefaultCodec
#     org.apache.hadoop.io.compress.GzipCodec
#     org.apache.hadoop.io.compress.BZip2Codec
#     com.hadoop.compression.lzo.LzoCodec
#     com.hadoop.compression.lzo.LzopCodec
#     org.apache.hadoop.io.compress.SnappyCodec 
# - Save changes
#
#
# 2) Configure Safety valves (JAVA_LIBRARY_PATH, HADOOP_LIBRARY_PATH)
# - Goto Home => Map Reduce => Configuration
# - Search for "MapReduce Service Environment Advanced Configuration Snippet (Safety Valve)"
# - Add the following values:
#     HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/usr/lib/hadoop/lib/*
#     JAVA_LIBRARY_PATH=$JAVA_LIBRARY_PATH:/usr/lib/hadoop/lib/native
#
#
# 3) Redeploy settings to hosts
# - Goto Deploy client configurations
#
#
# 4) Restart cluster
# - Restart cluster
#
# Note: 
#   Use locate lzo to get an idea of where the libs are installed
#
# See:
#   https://jira.oicr.on.ca/browse/DCC-1482
#
# See also:
#   https://code.google.com/a/apache-extras.org/p/hadoop-gpl-compression/wiki/FAQ
#   http://www.cloudera.com/content/cloudera-content/cloudera-docs/CM4Ent/4.6.2/Cloudera-Manager-Installation-Guide/cmig_install_LZO_Compression.html
#
################################################################################


# TODO: Should remove mongodb dependency, this is just used for overarch to init release db
- name: Setting up main ETL node
  hosts: main
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  vars:
    job_tracker: "{{ server_prefix }}-etl-worker-01:8021"
    default_fs: "hdfs://{{ server_prefix }}-etl-worker-01"
    postgresql_uri: "jdbc:postgresql://{{ server_prefix }}-etl-postgres/fathmm?user=dcc&password=dcc"
    mongo_base_uri: "mongodb://{{ server_prefix }}-etl-mongo"
    identifier_uri: "http://{{ server_prefix }}-etl-identifier:6381"
    elasticsearch_uri: "es://{{ server_prefix }}-etl-elasticsearch:9300"
  pre_tasks:
    - name: Install Java
      include: tasks/install-java.yml
    - name: Setup CDH repositories
      include: tasks/install-cdh-repository.yml
    - name: update apt repositories
      action: shell apt-get update ; true
  roles:
    - mongodb
    - etl
  tags:
    - second



- name: Install annotator component on ETL Main
  hosts: main
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  vars:
    - job_tracker: "{{ server_prefix }}-etl-worker-01:8021"
    - default_fs: "hdfs://{{ server_prefix }}-etl-worker-01"
  roles:
    - annotator
  tags:
    - second


- name: Install exporter component on ETL Main
  hosts: main
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  vars:
    - job_tracker: "{{ server_prefix }}-etl-worker-01:8021"
    - default_fs: "hdfs://{{ server_prefix }}-etl-worker-01"
    - zookeeper_quorum: "{{ server_prefix }}-etl-worker-01"
  roles:
    - exporter
  tags:
    - second



################################################################################
# FIXME: Bootstrap dcc-genome in mongodb
# Need newer importer to be online, right now just copy from local 
################################################################################
- name: Bootstrap dcc-genome
  hosts: mongo
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - name: Copy dcc-genes
      copy: src="/Users/dchang/mongodb-osx-x86_64-2.4.1/bin/dump/dcc-genome" dest="/tmp/" mode=0777
    - name: Bootstrap Gene
      shell: mongorestore --db dcc-genome --collection Gene /tmp/dcc-genome/Gene.bson
    - name: Bootstrap Pathway
      shell: mongorestore --db dcc-genome --collection Pathway /tmp/dcc-genome/Pathway.bson
    - name: Bootstrap Gene List
      shell: mongorestore --db dcc-genome --collection GeneList /tmp/dcc-genome/GeneList.bson
  tags:
    - second




# Install downloader component (not actually installled on the hosts)
- name: Install downloader
  hosts: main
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  vars:
    job_tracker: "{{ server_prefix }}-etl-worker-01:8021"
    name_node: "hdfs://{{ server_prefix }}-etl-worker-01:8020"
    zookeeper_quorum: "{{ server_prefix }}-etl-worker-01"
    env:
      HADOOP_USER_NAME: hdfs
  roles:
    - downloader
  tags:
    - second
    - debug




