################################################################################
# Brings up DCC ETL pipeline:
#
# - Initial hosts allocation
# - Provision Openstack instances and divide into logical groups
# - Create and distribute custom host files for openstack
# - Install Postgresql database server
# - Install ICGC DCC schemas
# - Provision DCC Identifier
# - Provision MongoDB server
# - Provision ElasticSearch server
# - Copy reference data to worker nodes
# - Install LZO on worker nodes
# - Provision Cloudera Manager
#
# - >>> Manually provision the cluster through Cloudera Manager <<<
#
# - Install packages on main ETL Node
# - Install etl scripts, reference data on ETL node
# - Install annotator on main ETL node
# - Install reference data for annotator
# - Patch scripts and configuration files for openstack environment
# - Bootstrap dcc-genome on mongodb server
# - Install exporter on main ETL node
# - Install downloader and its workflows into the cluster
#
#
# Note the playbook makes assumptions of which one of hadoop nodes
# is the jobtracker, name-node, quorum..etc
#
# Usage:
#   ./runAnsible etl_main.yml <tags>
#
################################################################################



################################################################################
#
# Post provisioning steps: Do these before starting an ETL run 
#
# - Copy projects' submission files to hdfs
# - Create project.json configuration
# - Download the dictionary for the ETL run
# - Download codelist for the ETL run??
# 
# 
# FIXME: not a good way to handle this
# 1) Patch exporter setenv.sh 
#   - The datatype declaration should only contain the data types that we have, otherwise 
#     the dynamic exporter will throw an exception and halt the overarching script. This
#     is difficult to do programmatically as we don't know that projects have what types.
#
# 2) (Re)create oozie workflow for coordinator (archivecleaner)
#   - Goto a oozie server
#   - Copy job.properties from HDFS     hadoop fs -copyToLocal /user/downloader/workflows/archivecleaner-main/job.properties job.properties
#   - Get job id if exists     oozie jobs -oozie http://localhost:11000/oozie -jobtype coordinator
#   - Kill job if exists       oozie job -oozie http://localhost:11000/oozie -kill <Coordinator job_id from above>
#   - Install coordinator      oozie job -oozie http://localhost:11000/oozie -config job.properties -submit
#   - Start coordinator        oozie job -oozie http://localhost:11000/oozie -start <New coordinator job_id>
#
################################################################################

- name: Generate initial hosts
  hosts: localhost
  gather_facts: False
  tasks:
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-postgres" 
                groups=group_01
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-identifier" 
                groups=group_02
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-cm" 
                groups=group_03
    - name: "Adding host"
      add_host: name="{{ item }}" 
                groups=group_04
      with_sequence: count=4 
                     format="{{ server_prefix }}-etl-worker-%02x"
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-mongo" 
                groups=group_05
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-main" 
                groups=group_06
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-elasticsearch" 
                groups=group_07
    - name: "Adding host"
      add_host: name="{{ server_prefix }}-etl-test" 
                groups=group_08
  tags:
    - launch
    - debug

- name: Create Openstack host file
  hosts: localhost
  gather_facts: False
  tasks:
    - name: "Remove previous host file if exist"
      shell: rm -f bootstrap_hosts
      delegate_to: localhost
    - name: "Create new host file with localhost entry"
      shell: echo "127.0.0.1 localhost" > bootstrap_hosts
      delegate_to: localhost
  tags:
    - launch
    - debug


################################################################################
#           Start creating OpenStack instances.                                #
################################################################################

- name: Provision OpenStack Instance
  hosts: group_01
  user: root
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} 
                groups=postgres,all_instances 
                hostname={{ inventory_hostname }}
  tags:
    - launch
    - debug


- name: Provision OpenStack Instance
  hosts: group_02
  user: root
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} 
                groups=identifier,all_instances 
                hostname={{ inventory_hostname }}
  tags:
    - launch
    - debug


- name: Provision OpenStack Instance
  hosts: group_03
  user: root
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} 
                groups=manager,all_instances 
                hostname={{ inventory_hostname }}
    - name: Save manager's public IP for later
      set_fact: cm_host={{ data.public_ip }}
  tags:
    - launch
    - debug


- name: Provision OpenStack Instance
  hosts: group_04
  user: root
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} 
                groups=workers,all_instances 
                hostname={{ inventory_hostname }}
  tags:
    - launch
    - debug


- name: Provision OpenStack Instance
  hosts: group_05
  user: root
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} 
                groups=mongo,all_instances 
                hostname={{ inventory_hostname }}
  tags:
    - launch
    - debug


- name: Provision OpenStack Instance
  hosts: group_06
  user: root
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} 
                groups=main,all_instances 
                hostname={{ inventory_hostname }}
  tags:
    - launch
    - debug


- name: Provision OpenStack Instance
  hosts: group_07
  user: root
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - include: tasks/create-instances.yml
    - name: Add public ip to hostgroup
      add_host: name={{ data.public_ip }} 
                groups=elasticsearch,all_instances 
                hostname={{ inventory_hostname }}
  tags:
    - launch
    - debug


################################################################################
#           Getting around openstack quirkyness of not having                  #
################################################################################

- name: Check if SSH is ready on servers
  hosts: all_instances
  gather_facts: False
  tasks:
    - name: Wait for ssh
      wait_for: host={{ inventory_hostname }} 
                port=22 
                timeout=900
      delegate_to: localhost
  tags:
    - launch

- name: Grab openstack node's internal IPs
  hosts: all_instances
  gather_facts: True
  vars_files:
    - "vars/main.yml"
  vars:
    host_key_checking: False
    ansible_ssh_user: ubuntu
  tasks:
    - name: Writing IPs to host file
      shell: echo "{{ ansible_all_ipv4_addresses[0] }} {{ ansible_hostname }}" >> bootstrap_hosts
      delegate_to: localhost
  tags:
    - launch

- name: Replace /etc/hosts with bootstrapped hosts file
  hosts: all_instances
  sudo: True
  vars_files:
    - "vars/main.yml"
  vars:
    host_key_checking: False
    ansible_ssh_user: ubuntu
  tasks:
    - name: Copying... 
      copy: src=bootstrap_hosts 
            dest=/etc/hosts 
            owner=root 
            group=root
  tags:
    - launch


################################################################################
#                           Provision each host.                               #
################################################################################

- name: Install postgresql database server
  hosts: postgres
  sudo: True
  gather_facts: True
  vars_files:
    - "vars/main.yml"
  roles:
    - postgres
  tags:
    - provision


- name: Bootstrap databases
  hosts: postgres
  sudo_user: postgres
  sudo: True
  gather_facts: True
  vars_files:
    - "vars/main.yml"
  roles:
    - postgresData
  tags:
    - provision


# Generated password for ansible postgres???
# $ echo "md5`echo -n "dccdcc" | md5`"

- name: Provision Identifier
  hosts: identifier
  sudo: True
  gather_facts: True
  vars_files:
    - "vars/main.yml"
  vars:
    identifier_url: "jdbc:postgresql://{{ server_prefix }}-etl-postgres:5432/dcc_identifier"
  pre_tasks:
    - name: Install Java
      include: tasks/install-java.yml
  roles:
    - identifier
  tags:
    - provision
  

- name: Setting up MongoDB
  hosts: mongo 
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  roles:
    - mongodb
  tags:
    - provision


- name: Setting up Elasticsearch Node
  hosts: elasticsearch
  sudo: True
  gather_facts: False
  vars_files: 
    - "vars/main.yml"
  vars:
    es_cluster_name: elasticsearch 
  pre_tasks:
    - name: Install Java
      include: tasks/install-java.yml
  roles:
    - elasticsearch
  tags:
    - provision


- name: Setting up Cloudera Manager
  hosts: manager
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - name: Setup CDH repositories
      include: tasks/install-cdh-repository.yml
    - name: Install Java
      include: tasks/install-java.yml

    - name: Update apt-get 
      apt:  update_cache=yes
    
    - name: Install apt packages
      apt:  pkg={{ item }} 
            state=latest
      with_items:
        - python-apt
        - ntp
        - sudo
        - tree
        - curl
        - cloudera-manager-daemons
        - cloudera-manager-server-db
        - cloudera-manager-server
      environment: proxy_env
    
    - name: Start services
      service:  name={{ item }} 
                state=started
      with_items:
        - ntp
        - cloudera-scm-server-db
        - cloudera-scm-server
  tags:
    - provision

- name: Install LZO
  hosts: main:workers
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - name: Get extra repo
      copy: src="files/gplextras.list" 
            dest="/etc/apt/sources.list.d/gplextras.list" 
            mode=0644 
            force=yes
    - name: Update apt-get 
      apt:  update_cache=yes
    - name: Install apt packages
      apt:  pkg={{ item }} 
            state=installed
      with_items:
        - liblzo2-2
        - hadoop-lzo
        - lzop
      environment: proxy_env
  tags:
    - provision
    - debug

- name: Provision Hadoop Cluster using Cloudera Manager API
  hosts: localhost
  connection: local
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  tasks:
    - name: Run Python script to setup cluster
      command: "python files/cluster_setup.py -p {{ ansible_ssh_private_key_file }} -h {{ hostvars['dcc-etl-cm']['cm_host'] }} "
  tags:
    - provision
    - debug


################################################################################
#                    Apply required configurations to each host.               #
################################################################################


# FIXME: Production uses /u/dcc_dev/ as a shared directory, we don't have this on openstack
- name: Copy reference genome to worker ndoes
  hosts: workers
  gather_facts: False
  sudo: True
  vars_files:
    - "vars/main.yml"
  tasks:
    - name: Ensure data directory
      file: path="{{ item }}" state="directory" mode=0777 
      with_items:
        - "{{ data_dir }}"
    - name: Copy genome
      get_url: "url={{ reference_genome_url }} dest={{ data_dir }}/{{ reference_genome_archive }} mode=0777"
    - name: Extract the reference genome 
      command: "tar xzf {{ data_dir }}/{{ reference_genome_archive }} -C {{ data_dir }}"
  tags:
    - config

# TODO: Should remove mongodb dependency, this is just used for overarch to init release db
- name: Setting up main ETL node
  hosts: main
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  vars:
    job_tracker: "{{ server_prefix }}-etl-worker-01:8021"
    default_fs: "hdfs://{{ server_prefix }}-etl-worker-01"
    postgresql_uri: "jdbc:postgresql://{{ server_prefix }}-etl-postgres/fathmm?user=dcc&password=dcc"
    mongo_base_uri: "mongodb://{{ server_prefix }}-etl-mongo"
    identifier_uri: "http://{{ server_prefix }}-etl-identifier:6381"
    elasticsearch_uri: "es://{{ server_prefix }}-etl-elasticsearch:9300"
  pre_tasks:
    - name: Install Java
      include: tasks/install-java.yml
    - name: Setup CDH repositories
      include: tasks/install-cdh-repository.yml
  roles:
    - mongodb
    - etl
  tags:
    - config


- name: Install annotator component on ETL Main
  hosts: main
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  vars:
    - job_tracker: "{{ server_prefix }}-etl-worker-01:8021"
    - default_fs: "hdfs://{{ server_prefix }}-etl-worker-01"
  roles:
    - annotator
  tags:
    - config


- name: Install exporter component on ETL Main
  hosts: main
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  vars:
    - job_tracker: "{{ server_prefix }}-etl-worker-01:8021"
    - default_fs: "hdfs://{{ server_prefix }}-etl-worker-01"
    - zookeeper_quorum: "{{ server_prefix }}-etl-worker-01"
  roles:
    - exporter
  tags:
    - config


# Install downloader component (not actually installled on the hosts)
- name: Install downloader
  hosts: main
  sudo: True
  gather_facts: False
  vars_files:
    - "vars/main.yml"
  vars:
    job_tracker: "{{ server_prefix }}-etl-worker-01:8021"
    name_node: "hdfs://{{ server_prefix }}-etl-worker-01:8020"
    zookeeper_quorum: "{{ server_prefix }}-etl-worker-01"
    env:
      HADOOP_USER_NAME: hdfs
  roles:
    - downloader
  tags:
    - config
    - debug




